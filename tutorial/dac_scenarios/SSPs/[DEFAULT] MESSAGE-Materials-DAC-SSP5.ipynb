{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce2dbbc",
   "metadata": {},
   "source": [
    "## Import all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db473272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (typeof IPython !== 'undefined') { IPython.OutputArea.prototype._should_scroll = function(lines){ return false; }}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pratama\\Documents\\GitHub\\MESSAGEix\\message_ix\\message_ix\\reporting\\__init__.py:98: FutureWarning: Importing from genno.computations will be deprecated in a future version; use genno.operator instead.\n",
      "  (\"tom:nl-t-yv-ya\", (genno.computations.add, \"fom:nl-t-yv-ya\", \"vom:nl-t-yv-ya\")),\n"
     ]
    }
   ],
   "source": [
    "import ixmp\n",
    "import message_ix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from collections.abc import Mapping\n",
    "from itertools import repeat\n",
    "from message_ix.models import MESSAGE_ITEMS\n",
    "from message_ix.utils import make_df\n",
    "from message_ix.tools.add_dac import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ed6e44e",
   "metadata": {},
   "source": [
    "def add_UE_share_constraints(\n",
    "    scen,\n",
    "    path_UE_share_input,\n",
    "    ssp=\"SSP2\",\n",
    "    start_year=None,\n",
    "    calibration_year=None,\n",
    "    period_interpol=4,\n",
    "    clean_relations=False,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"Add share constraints for end-use technologies.\n",
    "\n",
    "    The purpose of this script is to add share constraints for the end-use\n",
    "    sectors, thereby replacing any exisiting relation based share constraints\n",
    "    in the process.\n",
    "    The share constraint parametrization is read from an Excel-file and has\n",
    "    been setup so that it can be applied to all five SSPs. Some constraints\n",
    "    are applicable for multiple SSPs and nodes.\n",
    "    The share constraints are parameterized so that the total to which the\n",
    "    share is applied is derived based on a level/commodity and the\n",
    "    technologies contributing to a share are specified individually. Shares\n",
    "    with a value of 1. are not added to the model. In the process of adding\n",
    "    the share constraints, a check is undertaken to ensure that the share\n",
    "    constraint values do do not violate the calibrated baseyear shares. If\n",
    "    they do, then the baseyear share value is interpolated, so that the\n",
    "    target-share value as specied in the Excel-file are gradually achieved\n",
    "    over time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scen : :class:`message_ix.Scenario`\n",
    "        scenario to which changes should be applies\n",
    "    ssp : string\n",
    "        specify for which SSP the parameters should be added\n",
    "    start_year : int\n",
    "        specify the year as of which constraints should be added;\n",
    "        If None, then `firstmodelyear`\n",
    "    calibration_year : int\n",
    "        specify the last year for data has been calibrated\n",
    "        If None, the `firstmodelyear` -1\n",
    "    period_intpol : int (default=4)\n",
    "        the number of time periods (not years) over which deviations\n",
    "        converge\n",
    "    clean_relations : boolean\n",
    "        option whether to entirely remove all relation based UE share\n",
    "        constraints.\n",
    "    verbose : boolean (default=False)\n",
    "        option whether to primnt onscreen messages.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove all existing UE_ growth constraints\n",
    "    if clean_relations is True:\n",
    "        with scen.transact(\"Remove UE relations\"):\n",
    "            remove_rel = [r for r in scen.set(\"relation\") if r.find(\"UE_\") >= 0]\n",
    "            scen.remove_set(\"relation\", remove_rel)\n",
    "\n",
    "            remove_tec = [t for t in scen.set(\"technology\") if t.find(\"useful_\") >= 0]\n",
    "            scen.remove_set(\"technology\", remove_tec)\n",
    "\n",
    "    # Retrieve share constraint input data\n",
    "    data = pd.read_excel(path_UE_share_input)\n",
    "\n",
    "    # Retrieve list of scenario years\n",
    "    years = scen.set(\"year\").tolist()\n",
    "\n",
    "    # If start_year is None, set to `firstmodelyear`\n",
    "    if start_year is None:\n",
    "        start_year = scen.firstmodelyear\n",
    "\n",
    "    # If calibration_year is None, set to `firstmodelyear`\n",
    "    if calibration_year is None:\n",
    "        calibration_year = years[years.index(scen.firstmodelyear) - 1]\n",
    "\n",
    "    # Ensure that the data is relevant for the current SSP\n",
    "    data_gen = data.loc[data.SSP == \"all\"]\n",
    "    data_ssp = data.loc[data.SSP == ssp]\n",
    "\n",
    "    for i in data_ssp.index:\n",
    "        if data_ssp.loc[i, \"node\"] == \"all\":\n",
    "            data_gen = data_gen.loc[\n",
    "                ~(data_gen.share_name == data_ssp.loc[i, \"share_name\"])\n",
    "            ]\n",
    "        else:\n",
    "            data_gen = data_gen.loc[\n",
    "                ~(\n",
    "                    (data_gen.share_name == data_ssp.loc[i, \"share_name\"])\n",
    "                    & (data_gen.node == data_ssp.loc[i, \"node\"])\n",
    "                )\n",
    "            ]\n",
    "    data = pd.concat([data_ssp, data_gen]).reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "    # Start workflow to add parameters\n",
    "    with scen.transact(\"\"):\n",
    "        for i in data.index:\n",
    "            row = data.iloc[i]\n",
    "\n",
    "            if row.share_name in scen.set(\"relation\").tolist():\n",
    "                if verbose:\n",
    "                    print(f\"Removing relation {row.share_name}\")\n",
    "                scen.remove_set(\"relation\", row.share_name)\n",
    "\n",
    "            # Skip if share is 100%\n",
    "            if row.target_value == 1:\n",
    "                continue\n",
    "\n",
    "            # Derive individual elements required for parametrization\n",
    "            # Assign share names\n",
    "            share_name = row.share_name\n",
    "            if share_name not in scen.set(\"shares\").tolist():\n",
    "                if verbose:\n",
    "                    print(f\"Adding share {row.share_name}\")\n",
    "                scen.add_set(\"shares\", share_name)\n",
    "\n",
    "            # Derive names of share total and share\n",
    "            share_name_total = f\"{share_name}_total\"\n",
    "            share_name_share = f\"{share_name}_share\"\n",
    "\n",
    "            # Assign technologies\n",
    "            tec_list_share = row.share_tec.split(\",\")\n",
    "\n",
    "            # Ensure that the output of the technologies have the same output\n",
    "            # as defined for \"commodity\" and \"useful\"\n",
    "            check_output = scen.par(\"output\", filters={\"technology\": tec_list_share})[\n",
    "                [\"commodity\", \"level\"]\n",
    "            ].drop_duplicates()\n",
    "            assert row.commodity in check_output.commodity.tolist()\n",
    "            assert row.level in check_output.level.tolist()\n",
    "\n",
    "            # Retrieve all technologies which have an outout onto the desired\n",
    "            # \"commodity\" and \"level\"\n",
    "            output = scen.par(\n",
    "                \"output\", filters={\"level\": row.level, \"commodity\": row.commodity}\n",
    "            )\n",
    "            tec_list_total = output.technology.unique().tolist()\n",
    "\n",
    "            # Add technologies to new type_tec\n",
    "            for tec in tec_list_total:\n",
    "                cur_type_tec = scen.set(\n",
    "                    \"cat_tec\", filters={\"type_tec\": share_name_total}\n",
    "                ).technology.tolist()\n",
    "                if tec not in cur_type_tec:\n",
    "                    scen.add_cat(\"technology\", share_name_total, tec)\n",
    "\n",
    "            for tec in tec_list_share:\n",
    "                cur_type_tec = scen.set(\n",
    "                    \"cat_tec\", filters={\"type_tec\": share_name_share}\n",
    "                ).technology.tolist()\n",
    "                if tec not in cur_type_tec:\n",
    "                    scen.add_cat(\"technology\", share_name_share, tec)\n",
    "\n",
    "            # Define nodes, if \"all\" then all are retrieved from the output\n",
    "            # for which the target share technology is available\n",
    "            if row.node == \"all\":\n",
    "                nodes = output.loc[\n",
    "                    output.technology.isin(tec_list_share)\n",
    "                ].node_loc.unique()\n",
    "            else:\n",
    "                nodes = [f\"R12_{r}\" for r in row.node.split(\",\")]\n",
    "\n",
    "            # Assign type_tec to map_shares_commodity_total\n",
    "            for n in nodes:\n",
    "                df = pd.DataFrame(\n",
    "                    {\n",
    "                        \"shares\": share_name,\n",
    "                        \"node_share\": n,\n",
    "                        \"node\": n,\n",
    "                        \"type_tec\": share_name_total,\n",
    "                        \"mode\": output.loc[\n",
    "                            (output.technology.isin(tec_list_total))\n",
    "                            & (output.node_loc == n)\n",
    "                        ][\"mode\"]\n",
    "                        .unique()\n",
    "                        .tolist(),\n",
    "                        \"commodity\": row.commodity,\n",
    "                        \"level\": row.level,\n",
    "                    }\n",
    "                )\n",
    "                scen.add_set(\"map_shares_commodity_total\", df)\n",
    "\n",
    "            # Assign type_tec to map_shares_commodity_total\n",
    "            for n in nodes:\n",
    "                df = pd.DataFrame(\n",
    "                    {\n",
    "                        \"shares\": share_name,\n",
    "                        \"node_share\": n,\n",
    "                        \"node\": n,\n",
    "                        \"type_tec\": share_name_share,\n",
    "                        \"mode\": output.loc[\n",
    "                            (output.technology.isin(tec_list_share))\n",
    "                            & (output.node_loc == n)\n",
    "                        ][\"mode\"]\n",
    "                        .unique()\n",
    "                        .tolist(),\n",
    "                        \"commodity\": row.commodity,\n",
    "                        \"level\": row.level,\n",
    "                    }\n",
    "                )\n",
    "                scen.add_set(\"map_shares_commodity_share\", df)\n",
    "\n",
    "            # Derive shares of activity in the calibration_year\n",
    "            if calibration_year >= scen.firstmodelyear:\n",
    "                par = \"bound_activity_lo\"\n",
    "            else:\n",
    "                par = \"historical_activity\"\n",
    "            act_total = scen.par(\n",
    "                par,\n",
    "                filters={\n",
    "                    \"node_loc\": nodes,\n",
    "                    \"technology\": tec_list_total,\n",
    "                    \"year_act\": calibration_year,\n",
    "                },\n",
    "            )\n",
    "            act_total = act_total.groupby([\"node_loc\"]).sum(numeric_only=True)[\n",
    "                [\"value\"]\n",
    "            ]\n",
    "\n",
    "            act_share = scen.par(\n",
    "                \"bound_activity_lo\",\n",
    "                filters={\n",
    "                    \"node_loc\": nodes,\n",
    "                    \"technology\": tec_list_share,\n",
    "                    \"year_act\": calibration_year,\n",
    "                },\n",
    "            )\n",
    "            act_share = act_share.groupby([\"node_loc\"]).sum(numeric_only=True)[\n",
    "                [\"value\"]\n",
    "            ]\n",
    "\n",
    "            baseyear_share = round((act_share / act_total) * 1000) / 1000\n",
    "            baseyear_share = baseyear_share.dropna()\n",
    "\n",
    "            # Create timeseries for values\n",
    "            share_type = (\n",
    "                \"share_commodity_lo\"\n",
    "                if row.share_type == \"lower\"\n",
    "                else \"share_commodity_up\"\n",
    "            )\n",
    "\n",
    "            # If \"baseyear\" then add timeseries with baseyear values for all years\n",
    "            if row.target_value == \"baseyear\":\n",
    "                for n in nodes:\n",
    "                    if n not in baseyear_share.index.values:\n",
    "                        val = 0\n",
    "                    else:\n",
    "                        val = baseyear_share.loc[n].value\n",
    "                    df = pd.DataFrame(\n",
    "                        {\n",
    "                            \"shares\": share_name,\n",
    "                            \"node_share\": n,\n",
    "                            \"year_act\": [\n",
    "                                y for y in scen.set(\"year\") if y >= start_year\n",
    "                            ],\n",
    "                            \"time\": \"year\",\n",
    "                            \"value\": val,\n",
    "                            \"unit\": \"-\",\n",
    "                        }\n",
    "                    )\n",
    "                    scen.add_par(share_type, df)\n",
    "\n",
    "            else:\n",
    "                for n in nodes:\n",
    "                    if row.target_value == \"TS\":\n",
    "                        # Create timeseries dataframe\n",
    "                        ts = pd.DataFrame(\n",
    "                            row[[y for y in row.index if y in years]]\n",
    "                        ).rename(columns={i: \"value\"})\n",
    "                        ts.value = ts.value.astype(float)\n",
    "                    else:\n",
    "                        ts = pd.DataFrame(\n",
    "                            {\n",
    "                                \"year_act\": [y for y in years if y >= calibration_year],\n",
    "                                \"value\": row.target_value,\n",
    "                            }\n",
    "                        ).set_index(\"year_act\")\n",
    "                    if n not in baseyear_share:\n",
    "                        baseval = ts.iloc[0].value\n",
    "                    else:\n",
    "                        baseval = baseyear_share.loc[n].value\n",
    "                    # Check if timeseries value is smaller than baseyear_share\n",
    "                    check = True\n",
    "                    if row.share_type == \"lower\":\n",
    "                        # If lower, check if baseyear share value is smaller\n",
    "                        # than the target value if it is, then the interpolate\n",
    "                        # to gradually reduce the share.\n",
    "                        check = baseval < ts.iloc[0].value\n",
    "                    elif row.share_type == \"upper\":\n",
    "                        # If upper, check if baseyear share value is larger\n",
    "                        # than the target value if it is, then the interpolate\n",
    "                        # to gradually increase the share.\n",
    "                        check = baseval < ts.iloc[0].value\n",
    "                    if check == False:\n",
    "                        if calibration_year not in ts.index:\n",
    "                            ts = pd.concat(\n",
    "                                [\n",
    "                                    pd.DataFrame(\n",
    "                                        {\"year\": calibration_year, \"value\": [baseval]}\n",
    "                                    ).set_index(\"year\"),\n",
    "                                    ts,\n",
    "                                ]\n",
    "                            )\n",
    "                        else:\n",
    "                            ts.loc[calibration_year, \"value\"] = baseval\n",
    "                        ts.loc[\n",
    "                            years[\n",
    "                                years.index(calibration_year)\n",
    "                                + 1 : years.index(calibration_year)\n",
    "                                + period_interpol\n",
    "                            ],\n",
    "                            \"value\",\n",
    "                        ] = np.nan\n",
    "\n",
    "                        # Interpolate values\n",
    "                        ts = ts.interpolate(method=\"index\")\n",
    "\n",
    "                    # Assign the remaining index values\n",
    "                    ts = (\n",
    "                        ts.assign(\n",
    "                            shares=share_name, node_share=n, time=\"year\", unit=\"-\"\n",
    "                        )\n",
    "                        .reset_index()\n",
    "                        .rename(columns={\"index\": \"year_act\"})\n",
    "                    )\n",
    "\n",
    "                    # Filter out years >= the start_year, so the year as of\n",
    "                    # which parameters should be added\n",
    "                    ts = ts.loc[ts.year_act >= start_year]\n",
    "                    scen.add_par(share_type, ts)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41f3c482",
   "metadata": {},
   "source": [
    "ssps = [\"SSP5\"]\n",
    "\n",
    "versions ={\"v2\":{\"co2_rate\":30000,\n",
    "                 \"budget\":300},\n",
    "           \"v4\":{\"co2_rate\":35000,\n",
    "                 \"budget\":-300},\n",
    "           \"v5\":{\"co2_rate\":32000,\n",
    "                 \"budget\":-300}\n",
    "          }\n",
    "\n",
    "\n",
    "for ssp in ssps:\n",
    "    mp = ixmp.Platform()\n",
    "\n",
    "    sbase = message_ix.Scenario(mp, model=f\"SSP_{ssp}_v1.0\",\n",
    "                                scenario=f\"{ssp} - Low Overshoot\") #\n",
    "    \n",
    "    s2run = sbase.clone(\n",
    "        f\"SSP_{ssp}_v1.0\",\n",
    "        f\"{ssp} - Low Overshoot_Relaxed-CCS-v5\",\n",
    "        keep_solution=False,\n",
    "    )\n",
    "    s2run.check_out()\n",
    "    \n",
    "    # Relaxing co2 injection rate constraint\n",
    "    df2rem = s2run.par(\"bound_activity_up\",{\n",
    "        \"technology\":\"co2_stor_glb\"})\n",
    "    df2add = df2rem.copy()\n",
    "    df2add[\"value\"] = np.round(35000/3.667,0)\n",
    "    \n",
    "    s2run.remove_par(\"bound_activity_up\",df2rem)\n",
    "    s2run.add_par(\"bound_activity_up\", df2add)\n",
    "    \n",
    "    # Relaxing trans1 activity up\n",
    "    df2rem = s2run.par(\"bound_activity_up\",{\n",
    "        \"technology\":\"co2_trans1\"})\n",
    "    s2run.remove_par(\"bound_activity_up\",df2rem)\n",
    "    \n",
    "    \n",
    "    # updating emission bound\n",
    "    df2rem = s2run.par(\"bound_emission\",{\"node\":\"World\",\"type_emission\":\"TCE\",\"type_year\":\"cumulative\"})\n",
    "    df2add = df2rem.copy()\n",
    "    df2add[\"value\"] = -300\n",
    "    \n",
    "    s2run.remove_par(\"bound_emission\",df2rem)\n",
    "    s2run.add_par(\"bound_emission\", df2add)\n",
    "    \n",
    "    # increasing storage limit\n",
    "    df2rem = s2run.par(\"bound_activity_up\",{\"technology\":\"co2_storcumulative\"})\n",
    "    df2add = df2rem.copy()\n",
    "    df2add[\"value\"] = df2rem[\"value\"].mul(100)\n",
    "    \n",
    "    s2run.remove_par(\"bound_activity_up\",df2rem)\n",
    "    #s2run.add_par(\"bound_activity_up\", df2add)\n",
    "    \n",
    "    # Remove transport thing\n",
    "    s2run.remove_set(\"shares\", \"UE_transport_fossil_Minimum\")\n",
    "    s2run.add_set(\"technology\", ['meth_fc_trp','meth_ic_trp'])\n",
    "\n",
    "    s2run.commit(comment=f\"{ssp}_1000f all ssp param\")\n",
    "\n",
    "    input_path = \"C:/Users/pratama/Documents/GitHub/MESSAGEix/message_ix/tutorial/dac_scenarios/SSPs\"\n",
    "    file_name = \"/ue_share_constraints.xlsx\"\n",
    "    add_UE_share_constraints(\n",
    "            s2run, # scenario object\n",
    "            input_path+file_name, # path\n",
    "            ssp=\"SSP5\", # SSP-name i.e \"LED\"\n",
    "            start_year=2035, # the year as of which a constraint should be added, best this is the firstmodelyear for your case\n",
    "            calibration_year=2020, # 2020\n",
    "            clean_relations=False, # set to False\n",
    "            verbose=True, # set to True\n",
    "        )\n",
    "    print(\"it works\")\n",
    "\n",
    "    \n",
    "    s2run.solve(solve_options={'scaind': '1','lpmethod': '4'})\n",
    "    print(ssp, \"objective value:\", s2run.var(\"OBJ\")[\"lvl\"])\n",
    "\n",
    "    # Get Report\n",
    "    print(\"stor scenario:\", ssp)\n",
    "    scenariotec = ['dac_lt','dac_hte','dac_htg',]\n",
    "    scenario_report = get_report(s2run,scenariotec)\n",
    "\n",
    "    s2run.set_as_default()        \n",
    "    \n",
    "    # CLOSE CONNECTION\n",
    "    mp.close_db()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c7c388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSP_SSP5_v1.0 // SSP5 - Low Overshoot_Relaxed-CCS-v5\n",
      "Reporting standard variables\n",
      "processing Table: Resource|Extraction\n",
      "processing Table: Resource|Cumulative Extraction\n",
      "processing Table: Primary Energy\n",
      "processing Table: Primary Energy (substitution method)\n",
      "processing Table: Final Energy\n",
      "processing Table: Secondary Energy|Electricity\n",
      "processing Table: Secondary Energy|Heat\n",
      "processing Table: Secondary Energy\n",
      "processing Table: Secondary Energy|Gases\n",
      "processing Table: Secondary Energy|Solids\n",
      "processing Table: Emissions|CO2\n",
      "The difference between top-down and bottom-up accounting.\n",
      "processing Table: Emissions|BC\n",
      "processing Table: Emissions|OC\n",
      "processing Table: Emissions|CO\n",
      "processing Table: Emissions|N2O\n",
      "processing Table: Emissions|CH4\n",
      "processing Table: Emissions|NH3\n",
      "processing Table: Emissions|Sulfur\n",
      "processing Table: Emissions|NOx\n",
      "processing Table: Emissions|VOC\n",
      "processing Table: Emissions|HFC\n",
      "processing Table: Emissions\n",
      "processing Table: Emissions\n",
      "processing Table: Agricultural Demand\n",
      "processing Table: Agricultural Production\n",
      "processing Table: Fertilizer Use\n",
      "processing Table: Fertilizer\n",
      "processing Table: Food Waste\n",
      "processing Table: Food Demand\n",
      "processing Table: Forestry Demand\n",
      "processing Table: Forestry Production\n",
      "processing Table: Land Cover\n",
      "processing Table: Yield\n",
      "processing Table: Capacity\n",
      "processing Table: Capacity Additions\n",
      "processing Table: Cumulative Capacity\n",
      "processing Table: Efficiency\n",
      "processing Table: Population\n",
      "processing Table: Price\n",
      "processing Table: Useful Energy\n",
      "processing Table: Useful Energy\n",
      "processing Table: Trade\n",
      "processing Table: Investment|Energy Supply\n",
      "processing Table: GDP\n",
      "processing Table: Cost\n",
      "processing Table: GLOBIOM Feedback\n",
      "processing Table: Carbon Sequestration\n",
      "processing Table: Capital Cost\n",
      "processing Table: OM Cost|Fixed\n",
      "processing Table: OM Cost|Variable\n",
      "processing Table: Lifetime\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "no emissions included\n",
      "Starting to upload timeseries\n",
      "    region                                variable   unit       2035  \\\n",
      "0  R12_AFR                     Resource|Extraction  EJ/yr  14.387768   \n",
      "1  R12_AFR                Resource|Extraction|Coal  EJ/yr   4.582271   \n",
      "2  R12_AFR                 Resource|Extraction|Gas  EJ/yr   3.763678   \n",
      "3  R12_AFR    Resource|Extraction|Gas|Conventional  EJ/yr   3.763678   \n",
      "4  R12_AFR  Resource|Extraction|Gas|Unconventional  EJ/yr   0.000000   \n",
      "\n",
      "        2040       2045       2050      2055      2060       2070       2080  \\\n",
      "0  12.440035  11.921956  12.196241  9.163965  8.284950  10.181601  15.650454   \n",
      "1   3.531404   2.718263   2.220542  1.703943  1.304209   0.755566   0.427074   \n",
      "2   4.385387   5.850805   7.528411  5.713470  5.706561   8.245965  14.273419   \n",
      "3   4.385387   5.850805   7.528411  5.713470  5.706561   8.245965  14.273419   \n",
      "4   0.000000   0.000000   0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "\n",
      "        2090       2100       2110  \n",
      "0  20.790138  24.095669  28.815371  \n",
      "1   0.230393   0.112633   0.042126  \n",
      "2  19.868612  23.782279  28.504109  \n",
      "3  19.868612  23.782279  28.504109  \n",
      "4   0.000000   0.000000   0.000000  \n",
      "Finished uploading timeseries\n"
     ]
    }
   ],
   "source": [
    "import ixmp\n",
    "import message_ix\n",
    "\n",
    "from message_data.tools.post_processing.iamc_report_hackathon import (\n",
    "    report as reporting)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "setups = {#'SSP_SSP2_v1.0':'NPi2030_600f',\n",
    "          #'SSP_SSP5_v1.0':'NPi2030_700f',\n",
    "          #'SSP_SSP2_v1.0':'SSP2 - Low Overshoot_Relaxed-CCS',\n",
    "          #'SSP_SSP4_v1.0':'SSP4 - Low Overshoot_Relaxed-CCS',\n",
    "          #'SSP_SSP5_v1.0':'SSP5 - Low Overshoot_Relaxed-CCS-v2',\n",
    "          #'SSP_SSP5_v1.0':'SSP5 - Low Overshoot_Relaxed-CCS-v4',\n",
    "          'SSP_SSP5_v1.0':'SSP5 - Low Overshoot_Relaxed-CCS-v5',\n",
    "          }\n",
    "\n",
    "for key,val in setups.items():\n",
    "    print(key,'//',val)\n",
    "    mp = ixmp.Platform()\n",
    "    mo_name = key\n",
    "    sc_name = val\n",
    "    scen = message_ix.Scenario(mp, model=mo_name, scenario=sc_name)\n",
    "\n",
    "    # report(scenario)\n",
    "    print(\"Reporting standard variables\")\n",
    "    reporting(\n",
    "        mp,\n",
    "        scen,\n",
    "        # NB(PNK) this is not an error; .iamc_report_hackathon.report() expects a\n",
    "        #         string containing \"True\" or \"False\" instead of an actual bool.\n",
    "        \"False\",\n",
    "        scen.model,\n",
    "        scen.scenario,\n",
    "        merge_hist=True,\n",
    "        merge_ts=True,\n",
    "        run_config=\"materials_daccs_run_config.yaml\",\n",
    "    )\n",
    "    mp.close_db()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09f79184",
   "metadata": {},
   "source": [
    "colors = {\"SSP_SSP2_v1.0\":\"tab:orange\",\"SSP_SSP5_v1.0\":\"tab:purple\",\"SSP_SSP4_v1.0\":\"tab:blue\"}\n",
    "\n",
    "setups = {'SSP_SSP2_v1.0':'SSP2 - Low Overshoot_Relaxed-CCS-v2',\n",
    "          'SSP_SSP4_v1.0':'SSP4 - Low Overshoot_Relaxed-CCS-v2',\n",
    "          'SSP_SSP5_v1.0':'SSP5 - Low Overshoot_Relaxed-CCS-v2',\n",
    "          }"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad229d2e",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path = r'C:\\Users\\pratama\\Documents\\GitHub\\MESSAGEix\\message_data\\reporting_output'\n",
    "\n",
    "var_plot = ['Primary Energy|Nuclear',\n",
    "            'Primary Energy|Coal',\n",
    "            'Primary Energy|Oil',\n",
    "            'Primary Energy|Gas',\n",
    "            'Primary Energy|Biomass',\n",
    "            'Primary Energy|Geothermal',\n",
    "            'Primary Energy|Hydro',\n",
    "            'Primary Energy|Ocean',\n",
    "            'Primary Energy|Other',\n",
    "            'Primary Energy|Solar',\n",
    "            'Primary Energy|Wind']\n",
    "\n",
    "regions = [\"AFR\",\"CHN\",\"EEU\",\"FSU\",\"LAM\",\"MEA\",\"NAM\",\"PAO\",\"PAS\",\"RCPA\",\"SAS\",\"WEU\"]\n",
    "\n",
    "# SSP2\n",
    "f2name = '/SSP_SSP2_v1.0_SSP2 - Low Overshoot_Relaxed-CCS-v2.xlsx'\n",
    "df2 = pd.read_excel(path+f2name)\n",
    "df2 = df2.fillna('0')\n",
    "df2 = pyam.IamDataFrame(data=df2)\n",
    "\n",
    "# SSP4\n",
    "f4name = '/SSP_SSP4_v1.0_SSP4 - Low Overshoot_Relaxed-CCS-v2.xlsx'\n",
    "df4 = pd.read_excel(path+f4name)\n",
    "df4 = df4.fillna('0')\n",
    "df4 = pyam.IamDataFrame(data=df4)\n",
    "\n",
    "# SSP5\n",
    "f5name = '/SSP_SSP5_v1.0_SSP5 - Low Overshoot_Relaxed-CCS-v2.xlsx'\n",
    "df5 = pd.read_excel(path+f5name)\n",
    "df5 = df5.fillna('0')\n",
    "df5 = pyam.IamDataFrame(data=df5)\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(10,6), sharex=True, sharey=True)\n",
    "counter = 0\n",
    "for var in var_plot:\n",
    "    r = np.int(np.floor(counter/4))\n",
    "    c = np.int(counter - 4*r)\n",
    "    \n",
    "    data2_plot = list(df2.filter(region=\"World\", variable=var).timeseries().iloc[0])\n",
    "    data4_plot = list(df4.filter(region=\"World\", variable=var).timeseries().iloc[0])\n",
    "    data5_plot = list(df5.filter(region=\"World\", variable=var).timeseries().iloc[0])\n",
    "    \n",
    "    years = list(df2.timeseries().columns)\n",
    "        \n",
    "    axs[r,c].plot(years, data2_plot, label=f'SSP2 (Low-OS)')\n",
    "    axs[r,c].plot(years, data4_plot, label=f'SSP4 (Low-OS)')\n",
    "    axs[r,c].plot(years, data5_plot, label=f'SSP5 (Low-OS)')\n",
    "    \n",
    "    axs[r,c].set_title(var.replace('Primary Energy|',''))\n",
    "    \n",
    "    if c == 0:\n",
    "        axs[r,c].set_ylabel(\"Primary Energy\")\n",
    "        #axs[r,c].set_ylim(-22,52)\n",
    "        axs[r,c].set_xlim(2000,2100)\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "    \n",
    "axs[0,0].legend(ncol=1, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'sspreview_sv1/Primary Energy_GLB_timeseries.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2e17857",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path = r'C:\\Users\\pratama\\Documents\\GitHub\\MESSAGEix\\message_data\\reporting_output'\n",
    "\n",
    "var_plot = ['Emissions|CO2']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "\n",
    "for key,val in setups.items():\n",
    "    fname = f'/{key}_{val}.xlsx'\n",
    "    df = pd.read_excel(path+fname)\n",
    "    df = df.fillna('0')\n",
    "    df = pyam.IamDataFrame(data=df)\n",
    "    data = df.filter(region='World', variable=var_plot)\n",
    "\n",
    "    data_plot = {var: list(data.filter(variable=var).timeseries().div(1000).iloc[0])\n",
    "                          for var in var_plot}\n",
    "\n",
    "    years = list(data.timeseries().columns)\n",
    "    \n",
    "    sspname = key.replace('SSP_','').replace('_v1.0','')\n",
    "    for var in var_plot:\n",
    "        ax.plot(years, data_plot[var], label=f'{sspname}-Low Overshoot')\n",
    "ax.set_title(var_plot[0])\n",
    "\n",
    "ax.set_ylabel(\"Gt/y\")\n",
    "ax.set_ylim(-32,52)\n",
    "ax.set_xlim(2000,2100)\n",
    "ax.legend(ncol=1, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"sspreview_sv1/EmissionsCO2_GLB.png\",dpi=150)\n",
    "plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d71c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
